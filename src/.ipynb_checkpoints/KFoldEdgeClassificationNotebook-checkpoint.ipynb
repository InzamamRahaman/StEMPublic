{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import dataloaders\n",
    "import models\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics \n",
    "import sklearn.cluster as cluster\n",
    "import numpy as np \n",
    "import random\n",
    "import classifiers\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import sklearn.model_selection as model_selection\n",
    "import util\n",
    "import json\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_file = '../data/soc-sign-Slashdot081106-cleaned.csv'\n",
    "input_file = '../data/soc-sign-epinions-cleaned.csv'\n",
    "delimiter = ','\n",
    "ratio = 0.8\n",
    "data = dataloaders.UnsplitDataset(filepath=input_file, ratio=ratio, delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data.get_shuffled_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for PsuedoKernel \n",
    "num_nodes = data.get_num_nodes()\n",
    "dims = 16\n",
    "epochs = 100\n",
    "lr = 0.15\n",
    "lr_decay=0.0\n",
    "weight_decay=0.0\n",
    "lam = 0.00055\n",
    "p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fitter = models.fit_pseudo_kernel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(n_splits=num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131828\n",
      "99618.44480000001\n"
     ]
    }
   ],
   "source": [
    "len(X)/num_nodes\n",
    "print(num_nodes)\n",
    "print(len(X) * 0.8 * 0.148)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98964.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y == 0]) * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = 1\n",
    "delta0 = 0.5\n",
    "dims_array = [dims, 20, 20]\n",
    "frac1 = 0.148\n",
    "frac0 = 0.148\n",
    "p0 = True if frac0 > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "========================          Fold #1                    ========================\n",
      "======================================================================================\n",
      "The loss at epoch  1  was  0.6993435025215149\n",
      "The loss at epoch  2  was  0.8051214218139648\n",
      "The loss at epoch  3  was  0.6685885787010193\n",
      "The loss at epoch  4  was  0.6387786865234375\n",
      "The loss at epoch  5  was  0.6212530136108398\n",
      "The loss at epoch  6  was  0.6035315990447998\n",
      "The loss at epoch  7  was  0.5711809396743774\n",
      "The loss at epoch  8  was  0.5422701835632324\n",
      "The loss at epoch  9  was  0.5254396796226501\n",
      "The loss at epoch  10  was  0.5128694176673889\n",
      "The loss at epoch  11  was  0.5055877566337585\n",
      "The loss at epoch  12  was  0.5006917715072632\n",
      "The loss at epoch  13  was  0.4950365424156189\n",
      "The loss at epoch  14  was  0.48995521664619446\n",
      "The loss at epoch  15  was  0.49123409390449524\n",
      "The loss at epoch  16  was  0.4892246127128601\n",
      "The loss at epoch  17  was  0.49451833963394165\n",
      "The loss at epoch  18  was  0.4823787808418274\n",
      "The loss at epoch  19  was  0.47689375281333923\n",
      "The loss at epoch  20  was  0.4719988703727722\n",
      "The loss at epoch  21  was  0.48149731755256653\n",
      "The loss at epoch  22  was  0.4707031846046448\n",
      "The loss at epoch  23  was  0.46786344051361084\n",
      "The loss at epoch  24  was  0.4550493657588959\n",
      "The loss at epoch  25  was  0.4520440697669983\n",
      "The loss at epoch  26  was  0.4451298415660858\n",
      "The loss at epoch  27  was  0.44667989015579224\n",
      "The loss at epoch  28  was  0.438401460647583\n",
      "The loss at epoch  29  was  0.4397694170475006\n",
      "The loss at epoch  30  was  0.4306809604167938\n",
      "The loss at epoch  31  was  0.4295118749141693\n",
      "The loss at epoch  32  was  0.4241564869880676\n",
      "The loss at epoch  33  was  0.42502403259277344\n",
      "The loss at epoch  34  was  0.42035603523254395\n",
      "The loss at epoch  35  was  0.4201961159706116\n",
      "The loss at epoch  36  was  0.4168909192085266\n",
      "The loss at epoch  37  was  0.4171624481678009\n",
      "The loss at epoch  38  was  0.41446658968925476\n",
      "The loss at epoch  39  was  0.4143920838832855\n",
      "The loss at epoch  40  was  0.41182687878608704\n",
      "The loss at epoch  41  was  0.41305550932884216\n",
      "The loss at epoch  42  was  0.410004585981369\n",
      "The loss at epoch  43  was  0.41197410225868225\n",
      "The loss at epoch  44  was  0.40795743465423584\n",
      "The loss at epoch  45  was  0.4086796045303345\n",
      "The loss at epoch  46  was  0.40694060921669006\n",
      "The loss at epoch  47  was  0.4076177775859833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ccdee5fd56d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     kernel_model = models.fit_pseudo_kernel_model(num_nodes, dims, X, y, epochs=epochs, p=p, \n\u001b[1;32m     20\u001b[0m                                               \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             weight_decay=weight_decay, undersample=True)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mclf_pksem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     report = classifiers.train_and_evaluate_classifier(clf_pksem, kernel_model, X_train, y_train, X_test, y_test,\n",
      "\u001b[0;32m~/Desktop/SignEmb-3985b33de9ca5751ec59cf7b3596bf12bb298a21/src/models.py\u001b[0m in \u001b[0;36mfit_pseudo_kernel_model\u001b[0;34m(num_nodes, dims, X, y, epochs, lr, lr_decay, lam, p, weight_decay, ratio, undersample, print_loss)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m#print('Considering regularization...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpseudo_kernel_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reports_pksem = []\n",
    "reports_sine = []\n",
    "operation = 'hadamard'\n",
    "count = 1\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    \n",
    "    print(\"======================================================================================\")\n",
    "    \n",
    "    print(\"========================          Fold #{}                    ========================\".format(count))\n",
    "    \n",
    "    \n",
    "    print(\"======================================================================================\")\n",
    "    \n",
    "    \n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    \n",
    "    # train and evaluate pksem\n",
    "    kernel_model = models.fit_pseudo_kernel_model(num_nodes, dims, X, y, epochs=epochs, p=p, \n",
    "                                              lr=lr,lr_decay=lr_decay, lam=lam, \n",
    "                            weight_decay=weight_decay, undersample=True)\n",
    "    clf_pksem = linear_model.LogisticRegression()\n",
    "    report = classifiers.train_and_evaluate_classifier(clf_pksem, kernel_model, X_train, y_train, X_test, y_test,\n",
    "                                                    operation=operation, undersample=True, ratio=2)\n",
    "    reports_pksem.append(report)\n",
    "    \n",
    "    # train and evaluate SiNE\n",
    "    triples, triples0 = util.triples_from_array(X_train, y_train)\n",
    "    batch_size = int(frac1 * len(triples))\n",
    "    batch_size0 = int(frac0 * len(triples0))\n",
    "    sine_model = models.fit_sine_model(num_nodes, dims_array, triples, triples0, delta, delta0,\n",
    "                                   batch_size, batch_size0, epochs, lr=lr, lr_decay=lr_decay,\n",
    "                                  lam=lam, p=p, p0=p0)\n",
    "    clf_sine = linear_model.LogisticRegression()\n",
    "    report = classifiers.train_and_evaluate_classifier(clf_sine, sine_model, X_train, y_train, X_test, y_test,\n",
    "                                                    operation=operation, undersample=True, ratio=2)\n",
    "    reports_sine.append(report)\n",
    "    count += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_scores(reports, scores=['auc', 'average_percision_score', 'macro_f1', 'micro_f1', \n",
    "                                   'kappa', 'mathew']):\n",
    "    score_lst = dict()\n",
    "    for key in scores:\n",
    "        score_lst[key] = []\n",
    "    for report in reports:\n",
    "        for key in scores:\n",
    "            score_lst[key].append(report[key])\n",
    "    \n",
    "    score_avg = dict()\n",
    "    score_std = dict()\n",
    "    for key in scores:\n",
    "        score_avg[key] = np.mean(score_lst[key])\n",
    "        score_std[key] = np.std(score_lst[key])\n",
    "        \n",
    "    return score_avg, score_std\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = average_scores(reports_pksem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2 = average_scores(reports_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_link_pred_file = 'link-pred?epinions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(result_link_pred_file, 'a') as fp:\n",
    "    line = '{0},{1},{2},{3},{4},{5}\\n\\n'.format(input_file, operation, r1[0], r1[1], r2[0], r2[1])\n",
    "    fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(0.923 - 0.930)/0.923 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
