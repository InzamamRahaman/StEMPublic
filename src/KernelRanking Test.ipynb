{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import dataloaders\n",
    "import models\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics \n",
    "import sklearn.cluster as cluster\n",
    "import numpy as np \n",
    "import random\n",
    "import classifiers\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '../data/soc-sign-Slashdot081106-cleaned.csv'\n",
    "data = dataloaders.UnsplitDataset(filepath, ratio=0.8, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes = data.get_num_nodes()\n",
    "dims = 32\n",
    "epochs = 150\n",
    "lr = 0.5\n",
    "lr_decay=0.0\n",
    "weight_decay=0.0\n",
    "lam = 0.00055\n",
    "p = 2\n",
    "delta = 1\n",
    "delta0 = 0.5\n",
    "dims_array = [dims, 20, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triples, triples0 = data.get_training_triples(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = int(0.4 * len(triples))\n",
    "batch_size0 = int(0.4 * len(triples0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch  1  is  9.652932167053223\n",
      "Loss at epoch  2  is  7.042465686798096\n",
      "Loss at epoch  3  is  5.254761695861816\n",
      "Loss at epoch  4  is  4.088229179382324\n",
      "Loss at epoch  5  is  3.2051610946655273\n",
      "Loss at epoch  6  is  2.604398012161255\n",
      "Loss at epoch  7  is  2.2368404865264893\n",
      "Loss at epoch  8  is  2.0228469371795654\n",
      "Loss at epoch  9  is  1.846672773361206\n",
      "Loss at epoch  10  is  1.6613352298736572\n",
      "Loss at epoch  11  is  1.5205684900283813\n",
      "Loss at epoch  12  is  1.442103624343872\n",
      "Loss at epoch  13  is  1.3616595268249512\n",
      "Loss at epoch  14  is  1.2902873754501343\n",
      "Loss at epoch  15  is  1.2701016664505005\n",
      "Loss at epoch  16  is  1.2072794437408447\n",
      "Loss at epoch  17  is  1.19968843460083\n",
      "Loss at epoch  18  is  1.1360112428665161\n",
      "Loss at epoch  19  is  1.139007568359375\n",
      "Loss at epoch  20  is  1.065069317817688\n",
      "Loss at epoch  21  is  1.0859591960906982\n",
      "Loss at epoch  22  is  1.030713438987732\n",
      "Loss at epoch  23  is  1.0513665676116943\n",
      "Loss at epoch  24  is  0.9979242086410522\n",
      "Loss at epoch  25  is  1.0204966068267822\n",
      "Loss at epoch  26  is  0.9619516134262085\n",
      "Loss at epoch  27  is  0.989078164100647\n",
      "Loss at epoch  28  is  0.9377239942550659\n",
      "Loss at epoch  29  is  0.9671817421913147\n",
      "Loss at epoch  30  is  0.9198826551437378\n",
      "Loss at epoch  31  is  0.9443932771682739\n",
      "Loss at epoch  32  is  0.9023562669754028\n",
      "Loss at epoch  33  is  0.9278835654258728\n",
      "Loss at epoch  34  is  0.886021614074707\n",
      "Loss at epoch  35  is  0.9078257083892822\n",
      "Loss at epoch  36  is  0.8743939399719238\n",
      "Loss at epoch  37  is  0.8969260454177856\n",
      "Loss at epoch  38  is  0.8655902147293091\n",
      "Loss at epoch  39  is  0.8839238882064819\n",
      "Loss at epoch  40  is  0.8558706045150757\n",
      "Loss at epoch  41  is  0.8717970848083496\n",
      "Loss at epoch  42  is  0.8463441729545593\n",
      "Loss at epoch  43  is  0.8588113188743591\n",
      "Loss at epoch  44  is  0.834003210067749\n",
      "Loss at epoch  45  is  0.8483150005340576\n",
      "Loss at epoch  46  is  0.828374981880188\n",
      "Loss at epoch  47  is  0.8393659591674805\n",
      "Loss at epoch  48  is  0.8175671100616455\n",
      "Loss at epoch  49  is  0.8309342861175537\n",
      "Loss at epoch  50  is  0.8123220205307007\n",
      "Loss at epoch  51  is  0.8269971609115601\n",
      "Loss at epoch  52  is  0.8050929307937622\n",
      "Loss at epoch  53  is  0.8132078647613525\n",
      "Loss at epoch  54  is  0.8013178110122681\n",
      "Loss at epoch  55  is  0.8133993148803711\n",
      "Loss at epoch  56  is  0.7947777509689331\n",
      "Loss at epoch  57  is  0.8032854795455933\n",
      "Loss at epoch  58  is  0.7891908288002014\n",
      "Loss at epoch  59  is  0.7979694604873657\n",
      "Loss at epoch  60  is  0.7823386192321777\n",
      "Loss at epoch  61  is  0.7940927743911743\n",
      "Loss at epoch  62  is  0.7803300619125366\n",
      "Loss at epoch  63  is  0.7893615961074829\n",
      "Loss at epoch  64  is  0.7747097015380859\n",
      "Loss at epoch  65  is  0.7834615707397461\n",
      "Loss at epoch  66  is  0.7717899084091187\n",
      "Loss at epoch  67  is  0.781334400177002\n",
      "Loss at epoch  68  is  0.7675511837005615\n",
      "Loss at epoch  69  is  0.7763717174530029\n",
      "Loss at epoch  70  is  0.7644641995429993\n",
      "Loss at epoch  71  is  0.7728273868560791\n",
      "Loss at epoch  72  is  0.7592869997024536\n",
      "Loss at epoch  73  is  0.7691017389297485\n",
      "Loss at epoch  74  is  0.7568449974060059\n",
      "Loss at epoch  75  is  0.765979528427124\n",
      "Loss at epoch  76  is  0.7523994445800781\n",
      "Loss at epoch  77  is  0.7619376182556152\n",
      "Loss at epoch  78  is  0.7496552467346191\n",
      "Loss at epoch  79  is  0.7590945363044739\n",
      "Loss at epoch  80  is  0.7474179863929749\n",
      "Loss at epoch  81  is  0.756601095199585\n",
      "Loss at epoch  82  is  0.7445967197418213\n",
      "Loss at epoch  83  is  0.7527048587799072\n",
      "Loss at epoch  84  is  0.7422804832458496\n",
      "Loss at epoch  85  is  0.7520173788070679\n",
      "Loss at epoch  86  is  0.7398364543914795\n",
      "Loss at epoch  87  is  0.7485232353210449\n",
      "Loss at epoch  88  is  0.7381365299224854\n",
      "Loss at epoch  89  is  0.7471699118614197\n",
      "Loss at epoch  90  is  0.7358508110046387\n",
      "Loss at epoch  91  is  0.7436659336090088\n",
      "Loss at epoch  92  is  0.733116090297699\n",
      "Loss at epoch  93  is  0.7423731684684753\n",
      "Loss at epoch  94  is  0.7320299744606018\n",
      "Loss at epoch  95  is  0.7400561571121216\n",
      "Loss at epoch  96  is  0.7302225232124329\n",
      "Loss at epoch  97  is  0.7382715940475464\n",
      "Loss at epoch  98  is  0.7286829948425293\n",
      "Loss at epoch  99  is  0.7359410524368286\n",
      "Loss at epoch  100  is  0.7262508869171143\n",
      "Loss at epoch  101  is  0.7350673675537109\n",
      "Loss at epoch  102  is  0.7245663404464722\n",
      "Loss at epoch  103  is  0.7323588132858276\n",
      "Loss at epoch  104  is  0.723222017288208\n",
      "Loss at epoch  105  is  0.7318865656852722\n",
      "Loss at epoch  106  is  0.7215801477432251\n",
      "Loss at epoch  107  is  0.7287878394126892\n",
      "Loss at epoch  108  is  0.7197043299674988\n",
      "Loss at epoch  109  is  0.7286808490753174\n",
      "Loss at epoch  110  is  0.7180963754653931\n",
      "Loss at epoch  111  is  0.7254986763000488\n",
      "Loss at epoch  112  is  0.7167669534683228\n",
      "Loss at epoch  113  is  0.725272536277771\n",
      "Loss at epoch  114  is  0.7159953117370605\n",
      "Loss at epoch  115  is  0.7231553792953491\n",
      "Loss at epoch  116  is  0.7147456407546997\n",
      "Loss at epoch  117  is  0.7238650321960449\n",
      "Loss at epoch  118  is  0.7137882709503174\n",
      "Loss at epoch  119  is  0.7206652164459229\n",
      "Loss at epoch  120  is  0.7126561403274536\n",
      "Loss at epoch  121  is  0.7201113104820251\n",
      "Loss at epoch  122  is  0.7113661766052246\n",
      "Loss at epoch  123  is  0.7180877923965454\n",
      "Loss at epoch  124  is  0.7104678153991699\n",
      "Loss at epoch  125  is  0.7184884548187256\n",
      "Loss at epoch  126  is  0.7093511819839478\n",
      "Loss at epoch  127  is  0.7153626084327698\n",
      "Loss at epoch  128  is  0.7080375552177429\n",
      "Loss at epoch  129  is  0.715935468673706\n",
      "Loss at epoch  130  is  0.7070409059524536\n",
      "Loss at epoch  131  is  0.7129078507423401\n",
      "Loss at epoch  132  is  0.7061905860900879\n",
      "Loss at epoch  133  is  0.7138028740882874\n",
      "Loss at epoch  134  is  0.7055864334106445\n",
      "Loss at epoch  135  is  0.7130158543586731\n",
      "Loss at epoch  136  is  0.7045311331748962\n",
      "Loss at epoch  137  is  0.711838960647583\n",
      "Loss at epoch  138  is  0.7038717269897461\n",
      "Loss at epoch  139  is  0.710245668888092\n",
      "Loss at epoch  140  is  0.7031315565109253\n",
      "Loss at epoch  141  is  0.7094342708587646\n",
      "Loss at epoch  142  is  0.7020357847213745\n",
      "Loss at epoch  143  is  0.7087145447731018\n",
      "Loss at epoch  144  is  0.701531171798706\n",
      "Loss at epoch  145  is  0.7089450359344482\n",
      "Loss at epoch  146  is  0.7014756202697754\n",
      "Loss at epoch  147  is  0.7069892883300781\n",
      "Loss at epoch  148  is  0.7003269195556641\n",
      "Loss at epoch  149  is  0.7071957588195801\n",
      "Loss at epoch  150  is  0.6997769474983215\n"
     ]
    }
   ],
   "source": [
    "ranking_model = models.fit_ranking_model(num_nodes, dims_array[0], triples, triples0, delta, delta0,\n",
    "                                   batch_size, batch_size0, epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = data.get_training_set()\n",
    "X_test, y_test = data.get_testing_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembling training set features....\n",
      "Fitting classifier model\n",
      "Assembling testing set features\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "reports = classifiers.train_and_evaluate_classifier(clf, ranking_model, X_train, y_train, X_test, y_test,\n",
    "                                                    operation='concat', undersample=True, ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.75016481399777923,\n",
       " 'average_percision_score': 0.89758542317145329,\n",
       " 'classification_report': '             precision    recall  f1-score   support\\n\\n          0       0.54      0.39      0.45     24189\\n          1       0.83      0.90      0.86     79126\\n\\navg / total       0.76      0.78      0.77    103315\\n',\n",
       " 'confusion_matrix': array([[ 9453, 14736],\n",
       "        [ 8110, 71016]]),\n",
       " 'macro_f1': 0.65712678639607092,\n",
       " 'micro_f1': 0.77887044475632772}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750164813998\n"
     ]
    }
   ],
   "source": [
    "print(reports['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778870444756\n"
     ]
    }
   ],
   "source": [
    "print(reports['micro_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.39      0.45     24189\n",
      "          1       0.83      0.90      0.86     79126\n",
      "\n",
      "avg / total       0.76      0.78      0.77    103315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reports['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9453 14736]\n",
      " [ 8110 71016]]\n"
     ]
    }
   ],
   "source": [
    "print(reports['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24189\n",
      "79126\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test[y_test == 0]))\n",
    "print(len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23493200406523737"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test == 0])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23211779509267774"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 0])/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10010676556529557"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y == 0]) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798882681564246\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "for x, y in X_test[y_test == 0]:\n",
    "    x = Variable(torch.LongTensor([int(x)]))\n",
    "    y = Variable(torch.LongTensor([int(y)]))\n",
    "    output = kernel_model(x, y).data.numpy()[0]\n",
    "    neg = output[0]\n",
    "    pos = output[1]\n",
    "    count += 1 if neg > pos else 0\n",
    "print(count / len(X_test[y_test == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204247345409119\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "for x, y in X_test[y_test == 1]:\n",
    "    x = Variable(torch.LongTensor([int(x)]))\n",
    "    y = Variable(torch.LongTensor([int(y)]))\n",
    "    output = kernel_model(x, y).data.numpy()[0]\n",
    "    neg = output[0]\n",
    "    pos = output[1]\n",
    "    count += 1 if neg < pos else 0\n",
    "print(count / len(X_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798882681564246\n",
      "0.8204247345409119\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "A = []\n",
    "b = []\n",
    "for x, y in X_test[y_test == 0]:\n",
    "    x = Variable(torch.LongTensor([int(x)]))\n",
    "    y = Variable(torch.LongTensor([int(y)]))\n",
    "    output = kernel_model(x, y).data.numpy()[0]\n",
    "    neg = output[0]\n",
    "    pos = output[1]\n",
    "    A.append(pos)\n",
    "    b.append(0)\n",
    "    count += 1 if neg > pos else 0\n",
    "print(count / len(X_test[y_test == 0]))\n",
    "count = 0.0\n",
    "for x, y in X_test[y_test == 1]:\n",
    "    x = Variable(torch.LongTensor([int(x)]))\n",
    "    y = Variable(torch.LongTensor([int(y)]))\n",
    "    output = kernel_model(x, y).data.numpy()[0]\n",
    "    neg = output[0]\n",
    "    pos = output[1]\n",
    "    A.append(pos)\n",
    "    b.append(1)\n",
    "    count += 1 if neg < pos else 0\n",
    "print(count / len(X_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91300304628043227"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(b, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnergyToProbsLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnergyToProbsLayer, self).__init__()\n",
    "        self.transform = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        ones = torch.ones_like(x)\n",
    "        positive_prob = self.transform(x)\n",
    "        negative_prob = ones - positive_prob\n",
    "        output = torch.cat((negative_prob, positive_prob), dim=1)\n",
    "        #output = torch.log(output)\n",
    "        return output\n",
    "        \n",
    "\n",
    "class BilinearEmbeddingModel(nn.Module):\n",
    "    def __init__(self, num_nodes, dims=128):\n",
    "        super(BilinearEmbeddingModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_nodes + 1, dims)\n",
    "        self.initial_layer = nn.Linear(dims, int(dims/2))\n",
    "        self.initial_transform = nn.ReLU()\n",
    "        self.layer = nn.Bilinear(int(dims/2), int(dims/2), 1)\n",
    "        self.transform_layer= EnergyToProbsLayer()\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        x = Variable(torch.LongTensor([x]))\n",
    "        emb = self.embeddings(x)\n",
    "        transformed = self.initial_layer(emb)\n",
    "        emb = transformed.data.numpy()[0]\n",
    "        return emb\n",
    "\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u_emb = self.embeddings(u)\n",
    "        v_emb = self.embeddings(v)\n",
    "        u_emb = self.initial_transform(self.initial_layer(u_emb))\n",
    "        v_emb = self.initial_transform(self.initial_layer(v_emb))\n",
    "        energy = self.layer(u_emb, v_emb)\n",
    "        probs = self.transform_layer(energy)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pos = X_train[y_train == 1]\n",
    "X_train_neg = X_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25622"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_neg) - len(X_train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5881\n"
     ]
    }
   ],
   "source": [
    "batch_frac = 0.1\n",
    "epochs = 200\n",
    "alpha = 0.7\n",
    "dim = 32\n",
    "beta = 0.1\n",
    "size = data.get_num_nodes()\n",
    "print(size)\n",
    "model = BilinearEmbeddingModel(size, dim)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=alpha, lr_decay=beta)\n",
    "lam = 0.0055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3205\n",
      "2564\n"
     ]
    }
   ],
   "source": [
    "negative_batch_size = len(X_train_neg)\n",
    "positive_batch_size = int(0.8 * negative_batch_size)\n",
    "num_positive = len(X_train_pos)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=True)\n",
    "regularizer = lambda x: torch.norm(x - torch.zeros_like(x))\n",
    "print(negative_batch_size)\n",
    "print(positive_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration  0  is  \n",
      " 3.1082\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  1  is  \n",
      " 2.4626\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  2  is  \n",
      " 1.7610\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  3  is  \n",
      " 1.3609\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  4  is  \n",
      " 1.4519\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  5  is  \n",
      " 1.2471\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  6  is  \n",
      " 1.1656\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  7  is  \n",
      " 1.0918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  8  is  \n",
      " 1.0441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  9  is  \n",
      " 0.9981\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  10  is  \n",
      " 0.9836\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  11  is  \n",
      " 0.9513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  12  is  \n",
      " 0.9050\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  13  is  \n",
      " 0.8665\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  14  is  \n",
      " 0.8369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  15  is  \n",
      " 0.8063\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  16  is  \n",
      " 0.7851\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  17  is  \n",
      " 0.7630\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  18  is  \n",
      " 0.7481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  19  is  \n",
      " 0.7314\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  20  is  \n",
      " 0.7142\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  21  is  \n",
      " 0.7007\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  22  is  \n",
      " 0.6978\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  23  is  \n",
      " 0.6823\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  24  is  \n",
      " 0.6741\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  25  is  \n",
      " 0.6679\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  26  is  \n",
      " 0.6628\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  27  is  \n",
      " 0.6590\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  28  is  \n",
      " 0.6492\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  29  is  \n",
      " 0.6385\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  30  is  \n",
      " 0.6292\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  31  is  \n",
      " 0.6263\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  32  is  \n",
      " 0.6232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  33  is  \n",
      " 0.6148\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  34  is  \n",
      " 0.6156\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  35  is  \n",
      " 0.6042\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  36  is  \n",
      " 0.5991\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  37  is  \n",
      " 0.5953\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  38  is  \n",
      " 0.5904\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  39  is  \n",
      " 0.5849\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  40  is  \n",
      " 0.5808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  41  is  \n",
      " 0.5754\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  42  is  \n",
      " 0.5722\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  43  is  \n",
      " 0.5696\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  44  is  \n",
      " 0.5632\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  45  is  \n",
      " 0.5613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  46  is  \n",
      " 0.5567\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  47  is  \n",
      " 0.5560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  48  is  \n",
      " 0.5539\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  49  is  \n",
      " 0.5535\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  50  is  \n",
      " 0.5515\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  51  is  \n",
      " 0.5496\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  52  is  \n",
      " 0.5469\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  53  is  \n",
      " 0.5416\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  54  is  \n",
      " 0.5348\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  55  is  \n",
      " 0.5325\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  56  is  \n",
      " 0.5302\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  57  is  \n",
      " 0.5267\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  58  is  \n",
      " 0.5265\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  59  is  \n",
      " 0.5242\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  60  is  \n",
      " 0.5209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  61  is  \n",
      " 0.5230\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  62  is  \n",
      " 0.5227\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  63  is  \n",
      " 0.5234\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  64  is  \n",
      " 0.5252\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  65  is  \n",
      " 0.5179\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  66  is  \n",
      " 0.5157\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  67  is  \n",
      " 0.5118\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  68  is  \n",
      " 0.5102\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  69  is  \n",
      " 0.5096\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  70  is  \n",
      " 0.5087\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  71  is  \n",
      " 0.5077\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  72  is  \n",
      " 0.5098\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  73  is  \n",
      " 0.5090\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  74  is  \n",
      " 0.5131\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  75  is  \n",
      " 0.5083\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  76  is  \n",
      " 0.5076\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  77  is  \n",
      " 0.5034\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  78  is  \n",
      " 0.5010\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  79  is  \n",
      " 0.5034\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  80  is  \n",
      " 0.5017\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  81  is  \n",
      " 0.4990\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  82  is  \n",
      " 0.5009\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  83  is  \n",
      " 0.5010\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  84  is  \n",
      " 0.5013\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  85  is  \n",
      " 0.4998\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  86  is  \n",
      " 0.4980\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  87  is  \n",
      " 0.5007\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  88  is  \n",
      " 0.5002\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  89  is  \n",
      " 0.4976\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  90  is  \n",
      " 0.4982\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  91  is  \n",
      " 0.4971\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  92  is  \n",
      " 0.4945\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  93  is  \n",
      " 0.4958\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  94  is  \n",
      " 0.4916\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  95  is  \n",
      " 0.4947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  96  is  \n",
      " 0.4932\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  97  is  \n",
      " 0.4927\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  98  is  \n",
      " 0.4926\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  99  is  \n",
      " 0.4952\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  100  is  \n",
      " 0.4923\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  101  is  \n",
      " 0.4947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  102  is  \n",
      " 0.4912\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  103  is  \n",
      " 0.4947\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  104  is  \n",
      " 0.4926\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  105  is  \n",
      " 0.4907\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  106  is  \n",
      " 0.4905\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  107  is  \n",
      " 0.4902\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  108  is  \n",
      " 0.4899\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  109  is  \n",
      " 0.4907\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  110  is  \n",
      " 0.4894\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  111  is  \n",
      " 0.4896\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  112  is  \n",
      " 0.4917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  113  is  \n",
      " 0.4909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  114  is  \n",
      " 0.4883\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  115  is  \n",
      " 0.4842\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  116  is  \n",
      " 0.4872\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  117  is  \n",
      " 0.4847\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  118  is  \n",
      " 0.4838\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  119  is  \n",
      " 0.4860\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  120  is  \n",
      " 0.4842\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  121  is  \n",
      " 0.4860\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  122  is  \n",
      " 0.4835\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  123  is  \n",
      " 0.4830\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  124  is  \n",
      " 0.4850\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  125  is  \n",
      " 0.4814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration  126  is  \n",
      " 0.4825\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  127  is  \n",
      " 0.4871\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  128  is  \n",
      " 0.4828\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  129  is  \n",
      " 0.4860\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  130  is  \n",
      " 0.4814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  131  is  \n",
      " 0.4851\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  132  is  \n",
      " 0.4836\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  133  is  \n",
      " 0.4808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  134  is  \n",
      " 0.4819\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  135  is  \n",
      " 0.4827\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  136  is  \n",
      " 0.4815\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  137  is  \n",
      " 0.4833\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  138  is  \n",
      " 0.4833\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  139  is  \n",
      " 0.4823\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  140  is  \n",
      " 0.4820\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  141  is  \n",
      " 0.4833\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  142  is  \n",
      " 0.4822\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  143  is  \n",
      " 0.4841\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  144  is  \n",
      " 0.4845\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  145  is  \n",
      " 0.4823\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  146  is  \n",
      " 0.4796\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  147  is  \n",
      " 0.4834\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  148  is  \n",
      " 0.4795\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  149  is  \n",
      " 0.4802\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  150  is  \n",
      " 0.4835\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  151  is  \n",
      " 0.4805\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  152  is  \n",
      " 0.4813\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  153  is  \n",
      " 0.4813\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  154  is  \n",
      " 0.4815\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  155  is  \n",
      " 0.4789\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  156  is  \n",
      " 0.4778\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  157  is  \n",
      " 0.4808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  158  is  \n",
      " 0.4814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  159  is  \n",
      " 0.4778\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  160  is  \n",
      " 0.4782\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  161  is  \n",
      " 0.4795\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  162  is  \n",
      " 0.4796\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  163  is  \n",
      " 0.4795\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  164  is  \n",
      " 0.4798\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  165  is  \n",
      " 0.4819\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  166  is  \n",
      " 0.4786\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  167  is  \n",
      " 0.4807\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  168  is  \n",
      " 0.4812\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  169  is  \n",
      " 0.4795\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  170  is  \n",
      " 0.4778\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  171  is  \n",
      " 0.4780\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  172  is  \n",
      " 0.4804\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  173  is  \n",
      " 0.4772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  174  is  \n",
      " 0.4782\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  175  is  \n",
      " 0.4776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  176  is  \n",
      " 0.4787\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  177  is  \n",
      " 0.4752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  178  is  \n",
      " 0.4763\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  179  is  \n",
      " 0.4789\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  180  is  \n",
      " 0.4772\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  181  is  \n",
      " 0.4776\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  182  is  \n",
      " 0.4761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  183  is  \n",
      " 0.4788\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  184  is  \n",
      " 0.4773\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  185  is  \n",
      " 0.4793\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  186  is  \n",
      " 0.4758\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  187  is  \n",
      " 0.4816\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  188  is  \n",
      " 0.4765\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  189  is  \n",
      " 0.4803\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  190  is  \n",
      " 0.4779\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  191  is  \n",
      " 0.4781\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  192  is  \n",
      " 0.4789\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  193  is  \n",
      " 0.4767\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  194  is  \n",
      " 0.4773\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  195  is  \n",
      " 0.4778\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  196  is  \n",
      " 0.4759\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  197  is  \n",
      " 0.4741\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  198  is  \n",
      " 0.4761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss at iteration  199  is  \n",
      " 0.4752\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.zero_grad()\n",
    "\n",
    "    negative_batch = X_train_neg\n",
    "    positive_batch_idx = random.sample(range(num_positive), positive_batch_size)\n",
    "    positive_batch = X_train_pos[positive_batch_idx,:]\n",
    "    \n",
    "    \n",
    "    actual = [0] * negative_batch_size\n",
    "    actual1 = [1] * positive_batch_size\n",
    "    actual.extend(actual1)\n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    \n",
    "    all_inputs = np.concatenate((negative_batch, positive_batch), axis=0)\n",
    "    us = all_inputs[:,0]\n",
    "    vs = all_inputs[:,1]\n",
    "    \n",
    "    us = Variable(torch.LongTensor(us))\n",
    "    vs = Variable(torch.LongTensor(vs))\n",
    "    actual = Variable(torch.LongTensor(actual))\n",
    "    \n",
    "    #print('Computing loss....')\n",
    "    probs = model(us, vs)\n",
    "    #print('Number of probs ', len(probs))\n",
    "    #print(probs)\n",
    "    #print('Number of examples ', len(actual))\n",
    "    loss = criterion(probs, actual)\n",
    "    for parameter in model.parameters():\n",
    "        loss += lam * regularizer(parameter)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    print('Loss at iteration ', epoch, ' is ', loss.data)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "classifier = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding(model, x):\n",
    "    x_var = Variable(torch.LongTensor([x]))\n",
    "    emb = model.embeddings(x_var)\n",
    "    emb = model.initial_layer(emb)\n",
    "    emb = emb.data.numpy()[0]\n",
    "    return emb\n",
    "    \n",
    "\n",
    "def get_hadamard(model, x, y):\n",
    "    x_features = embedding(model, x)\n",
    "    y_features = embedding(model, y)\n",
    "    return x_features * y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor = get_hadamard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for x, y in X_train_neg:\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    inputs.append(feature_extractor(model, x, y))\n",
    "    outputs.append(0)\n",
    "\n",
    "positive_batch_idx = random.sample(range(num_positive), positive_batch_size)\n",
    "positive_batch = X_train_pos[positive_batch_idx,:]\n",
    "for x, y in positive_batch:\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    inputs.append(feature_extractor(model, x, y))\n",
    "    outputs.append(1)\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "3560\n",
      "3560\n"
     ]
    }
   ],
   "source": [
    "inputs1 = []\n",
    "expected_outputs1 = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x, y in X_test[y_test == 0]:\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    inputs1.append(feature_extractor(model, x, y))\n",
    "    expected_outputs1.append(0)\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "for x, y in X_test[y_test == 1]:\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    inputs1.append(feature_extractor(model, x, y))\n",
    "    expected_outputs1.append(1)\n",
    "    count += 1\n",
    "print(count)\n",
    "\n",
    "inputs1 = np.array(inputs1)\n",
    "expected_outputs1 = np.array(expected_outputs1)\n",
    "print(len(expected_outputs1))\n",
    "actual_outputs1 = classifier.predict(inputs1)\n",
    "actual_probs1 = classifier.predict_proba(inputs1)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75784200322129891"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(expected_outputs1, actual_outputs1, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88987068138279501"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(expected_outputs1, actual_probs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.77      0.58       358\n",
      "          1       0.97      0.90      0.94      3202\n",
      "\n",
      "avg / total       0.92      0.89      0.90      3560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(expected_outputs1, actual_outputs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3560"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expected_outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3560"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[y_test == 1]) + len(X_test[y_test == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 275,   83],\n",
       "       [ 315, 2887]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(expected_outputs1, actual_outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
