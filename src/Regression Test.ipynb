{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import dataloaders\n",
    "import models\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics \n",
    "import sklearn.cluster as cluster\n",
    "import numpy as np \n",
    "import random\n",
    "import classifiers\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_vot = '../data/bitcoinotc-cleaned.csv'\n",
    "output_file_nam = '../data/bitcoinotc-cleaned.csv'\n",
    "data = dataloaders.RegressionDataset(output_file_vot, output_file_nam, ratio=0.8, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes = data.get_num_nodes()\n",
    "dims = 32\n",
    "epochs = 200\n",
    "lr = 0.1\n",
    "lr_decay=0.0\n",
    "weight_decay=0.0\n",
    "lam = 0.00055\n",
    "X_train, y_train = data.get_training_set()\n",
    "X_test, y_test = data.get_testing_set()\n",
    "p = 2\n",
    "X = data.X\n",
    "y = data.y\n",
    "\n",
    "model_fitter = models.fit_pseudo_kernel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss at epoch  1  was  0.6944483518600464\n",
      "The loss at epoch  2  was  0.70699143409729\n",
      "The loss at epoch  3  was  0.6268907189369202\n",
      "The loss at epoch  4  was  0.603489339351654\n",
      "The loss at epoch  5  was  0.5837088227272034\n",
      "The loss at epoch  6  was  0.5581854581832886\n",
      "The loss at epoch  7  was  0.5141685009002686\n",
      "The loss at epoch  8  was  0.46782389283180237\n",
      "The loss at epoch  9  was  0.45148175954818726\n",
      "The loss at epoch  10  was  0.45075052976608276\n",
      "The loss at epoch  11  was  0.43370285630226135\n",
      "The loss at epoch  12  was  0.42875003814697266\n",
      "The loss at epoch  13  was  0.4158822298049927\n",
      "The loss at epoch  14  was  0.4134719669818878\n",
      "The loss at epoch  15  was  0.4125863313674927\n",
      "The loss at epoch  16  was  0.4085146188735962\n",
      "The loss at epoch  17  was  0.40044617652893066\n",
      "The loss at epoch  18  was  0.3986360728740692\n",
      "The loss at epoch  19  was  0.40023308992385864\n",
      "The loss at epoch  20  was  0.39684152603149414\n",
      "The loss at epoch  21  was  0.39647093415260315\n",
      "The loss at epoch  22  was  0.3953625559806824\n",
      "The loss at epoch  23  was  0.3913593292236328\n",
      "The loss at epoch  24  was  0.38925373554229736\n",
      "The loss at epoch  25  was  0.3861805498600006\n",
      "The loss at epoch  26  was  0.3886358141899109\n",
      "The loss at epoch  27  was  0.3865358233451843\n",
      "The loss at epoch  28  was  0.3900158703327179\n",
      "The loss at epoch  29  was  0.38898420333862305\n",
      "The loss at epoch  30  was  0.3829686939716339\n",
      "The loss at epoch  31  was  0.3848031461238861\n",
      "The loss at epoch  32  was  0.3823964595794678\n",
      "The loss at epoch  33  was  0.3887835144996643\n",
      "The loss at epoch  34  was  0.38522398471832275\n",
      "The loss at epoch  35  was  0.3847467303276062\n",
      "The loss at epoch  36  was  0.3818410038948059\n",
      "The loss at epoch  37  was  0.3808605968952179\n",
      "The loss at epoch  38  was  0.38193389773368835\n",
      "The loss at epoch  39  was  0.3759211301803589\n",
      "The loss at epoch  40  was  0.3824728727340698\n",
      "The loss at epoch  41  was  0.37960562109947205\n",
      "The loss at epoch  42  was  0.3791079819202423\n",
      "The loss at epoch  43  was  0.3806101977825165\n",
      "The loss at epoch  44  was  0.37532585859298706\n",
      "The loss at epoch  45  was  0.379769891500473\n",
      "The loss at epoch  46  was  0.3810109496116638\n",
      "The loss at epoch  47  was  0.3774702847003937\n",
      "The loss at epoch  48  was  0.3758434057235718\n",
      "The loss at epoch  49  was  0.3779359459877014\n",
      "The loss at epoch  50  was  0.37420204281806946\n",
      "The loss at epoch  51  was  0.37463128566741943\n",
      "The loss at epoch  52  was  0.37265413999557495\n",
      "The loss at epoch  53  was  0.37392458319664\n",
      "The loss at epoch  54  was  0.3738698959350586\n",
      "The loss at epoch  55  was  0.3699898421764374\n",
      "The loss at epoch  56  was  0.3728812634944916\n",
      "The loss at epoch  57  was  0.3771630823612213\n",
      "The loss at epoch  58  was  0.3718304932117462\n",
      "The loss at epoch  59  was  0.3739749789237976\n",
      "The loss at epoch  60  was  0.37098005414009094\n",
      "The loss at epoch  61  was  0.3718339502811432\n",
      "The loss at epoch  62  was  0.3731899857521057\n",
      "The loss at epoch  63  was  0.37073856592178345\n",
      "The loss at epoch  64  was  0.3702053129673004\n",
      "The loss at epoch  65  was  0.37163853645324707\n",
      "The loss at epoch  66  was  0.36983057856559753\n",
      "The loss at epoch  67  was  0.3695642352104187\n",
      "The loss at epoch  68  was  0.3666018843650818\n",
      "The loss at epoch  69  was  0.3703848123550415\n",
      "The loss at epoch  70  was  0.37032225728034973\n",
      "The loss at epoch  71  was  0.37005987763404846\n",
      "The loss at epoch  72  was  0.368948370218277\n",
      "The loss at epoch  73  was  0.36936241388320923\n",
      "The loss at epoch  74  was  0.36933931708335876\n",
      "The loss at epoch  75  was  0.369009792804718\n",
      "The loss at epoch  76  was  0.37089356780052185\n",
      "The loss at epoch  77  was  0.3749822676181793\n",
      "The loss at epoch  78  was  0.37087497115135193\n",
      "The loss at epoch  79  was  0.3698698580265045\n",
      "The loss at epoch  80  was  0.36812883615493774\n",
      "The loss at epoch  81  was  0.3690589368343353\n",
      "The loss at epoch  82  was  0.3706311881542206\n",
      "The loss at epoch  83  was  0.36702755093574524\n",
      "The loss at epoch  84  was  0.370350182056427\n",
      "The loss at epoch  85  was  0.3695995807647705\n",
      "The loss at epoch  86  was  0.3718714416027069\n",
      "The loss at epoch  87  was  0.36987677216529846\n",
      "The loss at epoch  88  was  0.37181466817855835\n",
      "The loss at epoch  89  was  0.3674851655960083\n",
      "The loss at epoch  90  was  0.36973440647125244\n",
      "The loss at epoch  91  was  0.3666747510433197\n",
      "The loss at epoch  92  was  0.36961835622787476\n",
      "The loss at epoch  93  was  0.3680720627307892\n",
      "The loss at epoch  94  was  0.36891549825668335\n",
      "The loss at epoch  95  was  0.3644459843635559\n",
      "The loss at epoch  96  was  0.36707577109336853\n",
      "The loss at epoch  97  was  0.365400493144989\n",
      "The loss at epoch  98  was  0.3698281943798065\n",
      "The loss at epoch  99  was  0.3683004379272461\n",
      "The loss at epoch  100  was  0.36649349331855774\n",
      "The loss at epoch  101  was  0.3679405450820923\n",
      "The loss at epoch  102  was  0.36642566323280334\n",
      "The loss at epoch  103  was  0.36574795842170715\n",
      "The loss at epoch  104  was  0.3709999620914459\n",
      "The loss at epoch  105  was  0.3690691888332367\n",
      "The loss at epoch  106  was  0.3637349009513855\n",
      "The loss at epoch  107  was  0.36607611179351807\n",
      "The loss at epoch  108  was  0.368356853723526\n",
      "The loss at epoch  109  was  0.3644888997077942\n",
      "The loss at epoch  110  was  0.36339354515075684\n",
      "The loss at epoch  111  was  0.3652859628200531\n",
      "The loss at epoch  112  was  0.36639291048049927\n",
      "The loss at epoch  113  was  0.36515912413597107\n",
      "The loss at epoch  114  was  0.3660317063331604\n",
      "The loss at epoch  115  was  0.36136677861213684\n",
      "The loss at epoch  116  was  0.3648890256881714\n",
      "The loss at epoch  117  was  0.36240139603614807\n",
      "The loss at epoch  118  was  0.3638072609901428\n",
      "The loss at epoch  119  was  0.362309068441391\n",
      "The loss at epoch  120  was  0.3634944260120392\n",
      "The loss at epoch  121  was  0.36419254541397095\n",
      "The loss at epoch  122  was  0.3619365394115448\n",
      "The loss at epoch  123  was  0.3637676239013672\n",
      "The loss at epoch  124  was  0.36716291308403015\n",
      "The loss at epoch  125  was  0.36216285824775696\n",
      "The loss at epoch  126  was  0.36451077461242676\n",
      "The loss at epoch  127  was  0.36667805910110474\n",
      "The loss at epoch  128  was  0.3641754388809204\n",
      "The loss at epoch  129  was  0.3668055832386017\n",
      "The loss at epoch  130  was  0.36335933208465576\n",
      "The loss at epoch  131  was  0.36285650730133057\n",
      "The loss at epoch  132  was  0.3639518618583679\n",
      "The loss at epoch  133  was  0.36464744806289673\n",
      "The loss at epoch  134  was  0.3632371127605438\n",
      "The loss at epoch  135  was  0.3661397695541382\n",
      "The loss at epoch  136  was  0.36273449659347534\n",
      "The loss at epoch  137  was  0.3614192008972168\n",
      "The loss at epoch  138  was  0.36658775806427\n",
      "The loss at epoch  139  was  0.3630698323249817\n",
      "The loss at epoch  140  was  0.36232560873031616\n",
      "The loss at epoch  141  was  0.3598272204399109\n",
      "The loss at epoch  142  was  0.36613377928733826\n",
      "The loss at epoch  143  was  0.36319270730018616\n",
      "The loss at epoch  144  was  0.3634718060493469\n",
      "The loss at epoch  145  was  0.3631196916103363\n",
      "The loss at epoch  146  was  0.3621017634868622\n",
      "The loss at epoch  147  was  0.366163045167923\n",
      "The loss at epoch  148  was  0.36379343271255493\n",
      "The loss at epoch  149  was  0.3627919852733612\n",
      "The loss at epoch  150  was  0.3602600693702698\n",
      "The loss at epoch  151  was  0.3616059422492981\n",
      "The loss at epoch  152  was  0.3633866012096405\n",
      "The loss at epoch  153  was  0.3629677891731262\n",
      "The loss at epoch  154  was  0.36224985122680664\n",
      "The loss at epoch  155  was  0.36163732409477234\n",
      "The loss at epoch  156  was  0.36049044132232666\n",
      "The loss at epoch  157  was  0.36166566610336304\n",
      "The loss at epoch  158  was  0.36212068796157837\n",
      "The loss at epoch  159  was  0.3613872826099396\n",
      "The loss at epoch  160  was  0.36223477125167847\n",
      "The loss at epoch  161  was  0.3651775121688843\n",
      "The loss at epoch  162  was  0.36100855469703674\n",
      "The loss at epoch  163  was  0.3621545135974884\n",
      "The loss at epoch  164  was  0.3648873567581177\n",
      "The loss at epoch  165  was  0.3598001003265381\n",
      "The loss at epoch  166  was  0.36300674080848694\n",
      "The loss at epoch  167  was  0.3633038401603699\n",
      "The loss at epoch  168  was  0.3611327111721039\n",
      "The loss at epoch  169  was  0.36165136098861694\n",
      "The loss at epoch  170  was  0.3623354434967041\n",
      "The loss at epoch  171  was  0.36412960290908813\n",
      "The loss at epoch  172  was  0.36199748516082764\n",
      "The loss at epoch  173  was  0.3621065318584442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss at epoch  174  was  0.36186888813972473\n",
      "The loss at epoch  175  was  0.3595693111419678\n",
      "The loss at epoch  176  was  0.36007922887802124\n",
      "The loss at epoch  177  was  0.3633401393890381\n",
      "The loss at epoch  178  was  0.36127105355262756\n",
      "The loss at epoch  179  was  0.36141589283943176\n",
      "The loss at epoch  180  was  0.3613925576210022\n",
      "The loss at epoch  181  was  0.36235737800598145\n",
      "The loss at epoch  182  was  0.3621450662612915\n",
      "The loss at epoch  183  was  0.3646529018878937\n",
      "The loss at epoch  184  was  0.35929709672927856\n",
      "The loss at epoch  185  was  0.360311895608902\n",
      "The loss at epoch  186  was  0.35956570506095886\n",
      "The loss at epoch  187  was  0.36146101355552673\n",
      "The loss at epoch  188  was  0.3622859716415405\n",
      "The loss at epoch  189  was  0.36171743273735046\n",
      "The loss at epoch  190  was  0.3606744408607483\n",
      "The loss at epoch  191  was  0.3603665232658386\n",
      "The loss at epoch  192  was  0.36017024517059326\n",
      "The loss at epoch  193  was  0.3624941110610962\n",
      "The loss at epoch  194  was  0.3586452603340149\n",
      "The loss at epoch  195  was  0.358741819858551\n",
      "The loss at epoch  196  was  0.36188942193984985\n",
      "The loss at epoch  197  was  0.36020907759666443\n",
      "The loss at epoch  198  was  0.3618578314781189\n",
      "The loss at epoch  199  was  0.3619212806224823\n",
      "The loss at epoch  200  was  0.3591398596763611\n"
     ]
    }
   ],
   "source": [
    "kernel_model = model_fitter(num_nodes, dims, X_train, y_train, epochs=epochs, p=p, \n",
    "                                              lr=lr,lr_decay=lr_decay, lam=lam, weight_decay=weight_decay, undersample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'concat'\n",
    "X = []\n",
    "y = []\n",
    "for u, v in X_train:\n",
    "    #print(u, v)\n",
    "    X.append(kernel_model.get_edge_features(int(u), int(v), method))\n",
    "    y.append(data.get_response(u, v))\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "y1 = []\n",
    "for u, v in X_test:\n",
    "    #print(u, v)\n",
    "    X1.append(kernel_model.get_edge_features(int(u), int(v), method))\n",
    "    y1.append(data.get_response(u, v))\n",
    "    \n",
    "X1 = np.array(X1)\n",
    "y1 = np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32774757169952928"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(metrics.mean_squared_error(y1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42764165696714906, 1.6539793037368739e-314)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.stats.pearsonr(y1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y1 * predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z[z < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6117"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z[z >= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
